# Atividades de Machine Learning - Semi-supervisionado e Auto-supervisionado

Este repositÃ³rio contÃ©m duas atividades prÃ¡ticas de aprendizado de mÃ¡quina:

1. **Atividade 1**: Aprendizado Semi-supervisionado (Auto-Treinamento) com SpamBase
2. **Atividade 2**: Aprendizado Auto-supervisionado (Autoencoder) com MNIST

## ğŸ“‹ Requisitos

### DependÃªncias Python

Instale as dependÃªncias necessÃ¡rias:

```bash
pip install scikit-learn numpy pandas matplotlib seaborn tensorflow jupyter
```

Ou use o arquivo `requirements.txt`:

```bash
pip install -r requirements.txt
```

## ğŸš€ Como Executar

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/tavs-coelho/slide5.git
cd slide5
```

### 2. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 3. Inicie o Jupyter Notebook

```bash
jupyter notebook
```

### 4. Execute os notebooks

- **Atividade 1**: Abra `atividade1_semi_supervisionado.ipynb`
- **Atividade 2**: Abra `atividade2_auto_supervisionado.ipynb`

Execute as cÃ©lulas em ordem (Cell > Run All ou Shift+Enter em cada cÃ©lula).

## ğŸ“š DescriÃ§Ã£o das Atividades

### Atividade 1 - Semi-supervisionado com SpamBase

**Objetivo**: Melhorar um classificador de spam usando poucos dados rotulados (10%) + pseudo-rotulagem dos dados nÃ£o rotulados (90%).

**Dataset**: SpamBase (OpenML id=44)
- 57 caracterÃ­sticas numÃ©ricas
- ClassificaÃ§Ã£o binÃ¡ria: spam vs. nÃ£o-spam

**O que serÃ¡ feito**:
1. Carregar dados e separar 10% rotulados, 90% nÃ£o rotulados
2. Treinar baseline (modelo supervisionado com apenas 10% dos dados)
3. Implementar auto-treinamento (self-training):
   - Fazer prediÃ§Ãµes nos dados nÃ£o rotulados
   - Selecionar prediÃ§Ãµes com alta confianÃ§a
   - Adicionar ao conjunto de treinamento
   - Retreinar modelo iterativamente
4. Comparar mÃ©tricas (F1, precisÃ£o, recall)
5. Gerar matriz de confusÃ£o e anÃ¡lise de erros

### Atividade 2 - Auto-supervisionado com MNIST

**Objetivo**: Aprender representaÃ§Ãµes sem rÃ³tulos via autoencoder e usÃ¡-las em tarefas de classificaÃ§Ã£o.

**Dataset**: MNIST
- Imagens 28Ã—28 pixels
- DÃ­gitos de 0 a 9

**O que serÃ¡ feito**:
1. Carregar, normalizar e achatar imagens MNIST
2. Construir e treinar um Autoencoder:
   - Encoder: comprime a imagem para representaÃ§Ã£o latente
   - Decoder: reconstrÃ³i a imagem a partir da representaÃ§Ã£o
3. Visualizar imagens originais vs. reconstruÃ­das
4. Usar as representaÃ§Ãµes aprendidas para classificaÃ§Ã£o
5. Comparar classificador com features do autoencoder vs. pixels brutos

## ğŸ“‚ Estrutura do RepositÃ³rio

```
slide5/
â”œâ”€â”€ README.md                              # Este arquivo
â”œâ”€â”€ requirements.txt                       # DependÃªncias Python
â”œâ”€â”€ atividade1_semi_supervisionado.ipynb   # Notebook Atividade 1
â””â”€â”€ atividade2_auto_supervisionado.ipynb   # Notebook Atividade 2
```

## ğŸ¯ Resultados Esperados

### Atividade 1
- Melhoria significativa de performance usando auto-treinamento
- F1-score do auto-treinamento > F1-score do baseline
- AnÃ¡lise de quais tipos de emails sÃ£o mais difÃ­ceis de classificar

### Atividade 2
- ReconstruÃ§Ã£o visual de dÃ­gitos MNIST
- DemonstraÃ§Ã£o de que features aprendidas sem supervisÃ£o podem ser Ãºteis
- ComparaÃ§Ã£o de performance entre diferentes abordagens

## ğŸ‘¨â€ğŸ’» Autor

Tavs Coelho

## ğŸ“ LicenÃ§a

Este projeto Ã© para fins educacionais.