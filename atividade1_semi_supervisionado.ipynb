{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 1 — Aprendizado Semi-supervisionado (Auto-Treinamento) com SpamBase\n",
    "\n",
    "## Objetivo\n",
    "Melhorar um classificador de spam usando poucos dados rotulados (10%) + pseudo-rotulagem dos dados não rotulados (90%).\n",
    "\n",
    "## Dataset\n",
    "SpamBase (OpenML id=44) - 57 características numéricas; classificação binária spam vs. não-spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações necessárias\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregar e Preparar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset SpamBase\n",
    "print(\"Carregando dataset SpamBase...\")\n",
    "data = fetch_openml(data_id=44, as_frame=True, parser='auto')\n",
    "\n",
    "X = data.data\n",
    "y = data.target.astype(int)  # 1=spam, 0=ham (não-spam)\n",
    "\n",
    "print(f\"Shape dos dados: {X.shape}\")\n",
    "print(f\"Distribuição de classes: \\n{pd.Series(y).value_counts()}\")\n",
    "print(f\"\\nPrimeiras linhas:\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dividir em Conjunto Rotulado (10%) e Não Rotulado (90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, separar conjunto de teste (20% do total)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Agora dividir o conjunto de treino em rotulado (10%) e não rotulado (90%)\n",
    "X_lab, X_unlab, y_lab, y_unlab = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.9, stratify=y_train_full, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dados rotulados: {X_lab.shape[0]} amostras\")\n",
    "print(f\"Dados não rotulados: {X_unlab.shape[0]} amostras\")\n",
    "print(f\"Dados de teste: {X_test.shape[0]} amostras\")\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_lab_scaled = scaler.fit_transform(X_lab)\n",
    "X_unlab_scaled = scaler.transform(X_unlab)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Supervisionado (Apenas 10% dos Dados Rotulados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo baseline com apenas dados rotulados\n",
    "print(\"Treinando modelo baseline...\")\n",
    "baseline_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "baseline_model.fit(X_lab_scaled, y_lab)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "y_pred_baseline = baseline_model.predict(X_test_scaled)\n",
    "\n",
    "# Métricas\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "baseline_precision = precision_score(y_test, y_pred_baseline)\n",
    "baseline_recall = recall_score(y_test, y_pred_baseline)\n",
    "baseline_f1 = f1_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(\"\\n=== RESULTADOS BASELINE ===\")\n",
    "print(f\"Acurácia: {baseline_accuracy:.4f}\")\n",
    "print(f\"Precisão: {baseline_precision:.4f}\")\n",
    "print(f\"Recall: {baseline_recall:.4f}\")\n",
    "print(f\"F1-Score: {baseline_f1:.4f}\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred_baseline, target_names=['Ham', 'Spam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Auto-Treinamento (Self-Training) com Pseudo-Rotulagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementação do algoritmo de Auto-Treinamento\n",
    "def self_training(X_labeled, y_labeled, X_unlabeled, threshold=0.95, max_iterations=10, batch_size=50):\n",
    "    \"\"\"\n",
    "    Algoritmo de Auto-Treinamento (Self-Training)\n",
    "    \n",
    "    Parâmetros:\n",
    "    - X_labeled: dados rotulados\n",
    "    - y_labeled: rótulos conhecidos\n",
    "    - X_unlabeled: dados não rotulados\n",
    "    - threshold: limite de confiança para pseudo-rotulagem\n",
    "    - max_iterations: número máximo de iterações\n",
    "    - batch_size: quantidade de amostras a adicionar por iteração\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copiar dados para não modificar os originais\n",
    "    X_train = X_labeled.copy()\n",
    "    y_train = y_labeled.copy()\n",
    "    X_pool = X_unlabeled.copy()\n",
    "    \n",
    "    history = {'iteration': [], 'labeled_samples': [], 'added_samples': []}\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        if len(X_pool) == 0:\n",
    "            print(f\"Iteração {iteration}: Pool de dados não rotulados vazio.\")\n",
    "            break\n",
    "            \n",
    "        # Treinar modelo com dados atuais\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Fazer predições no pool não rotulado\n",
    "        probas = model.predict_proba(X_pool)\n",
    "        max_probas = np.max(probas, axis=1)\n",
    "        predictions = model.predict(X_pool)\n",
    "        \n",
    "        # Selecionar amostras com alta confiança\n",
    "        confident_indices = np.where(max_probas >= threshold)[0]\n",
    "        \n",
    "        if len(confident_indices) == 0:\n",
    "            print(f\"Iteração {iteration}: Nenhuma amostra com confiança >= {threshold}\")\n",
    "            break\n",
    "        \n",
    "        # Limitar o número de amostras adicionadas\n",
    "        if len(confident_indices) > batch_size:\n",
    "            # Selecionar as mais confiantes\n",
    "            top_indices = np.argsort(max_probas[confident_indices])[-batch_size:]\n",
    "            confident_indices = confident_indices[top_indices]\n",
    "        \n",
    "        # Adicionar ao conjunto de treino\n",
    "        X_to_add = X_pool[confident_indices]\n",
    "        y_to_add = predictions[confident_indices]\n",
    "        \n",
    "        X_train = np.vstack([X_train, X_to_add])\n",
    "        y_train = np.concatenate([y_train, y_to_add])\n",
    "        \n",
    "        # Remover do pool não rotulado\n",
    "        X_pool = np.delete(X_pool, confident_indices, axis=0)\n",
    "        \n",
    "        # Registrar histórico\n",
    "        history['iteration'].append(iteration)\n",
    "        history['labeled_samples'].append(len(y_train))\n",
    "        history['added_samples'].append(len(confident_indices))\n",
    "        \n",
    "        print(f\"Iteração {iteration}: Adicionadas {len(confident_indices)} amostras. Total rotulado: {len(y_train)}\")\n",
    "    \n",
    "    return X_train, y_train, history\n",
    "\n",
    "# Executar auto-treinamento\n",
    "print(\"Iniciando Auto-Treinamento...\\n\")\n",
    "X_train_st, y_train_st, history = self_training(\n",
    "    X_lab_scaled, y_lab, X_unlab_scaled, \n",
    "    threshold=0.95, max_iterations=10, batch_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar evolução do auto-treinamento\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['iteration'], history['labeled_samples'], marker='o')\n",
    "plt.xlabel('Iteração')\n",
    "plt.ylabel('Total de Amostras Rotuladas')\n",
    "plt.title('Crescimento do Conjunto de Treinamento')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(history['iteration'], history['added_samples'])\n",
    "plt.xlabel('Iteração')\n",
    "plt.ylabel('Amostras Adicionadas')\n",
    "plt.title('Amostras Pseudo-Rotuladas por Iteração')\n",
    "plt.grid(True, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo final com dados aumentados\n",
    "print(\"\\nTreinando modelo final com auto-treinamento...\")\n",
    "st_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "st_model.fit(X_train_st, y_train_st)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "y_pred_st = st_model.predict(X_test_scaled)\n",
    "\n",
    "# Métricas\n",
    "st_accuracy = accuracy_score(y_test, y_pred_st)\n",
    "st_precision = precision_score(y_test, y_pred_st)\n",
    "st_recall = recall_score(y_test, y_pred_st)\n",
    "st_f1 = f1_score(y_test, y_pred_st)\n",
    "\n",
    "print(\"\\n=== RESULTADOS AUTO-TREINAMENTO ===\")\n",
    "print(f\"Acurácia: {st_accuracy:.4f}\")\n",
    "print(f\"Precisão: {st_precision:.4f}\")\n",
    "print(f\"Recall: {st_recall:.4f}\")\n",
    "print(f\"F1-Score: {st_f1:.4f}\")\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred_st, target_names=['Ham', 'Spam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparação de Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar métricas\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'Baseline (10%)': [baseline_accuracy, baseline_precision, baseline_recall, baseline_f1],\n",
    "    'Auto-Treinamento': [st_accuracy, st_precision, st_recall, st_f1]\n",
    "}, index=['Acurácia', 'Precisão', 'Recall', 'F1-Score'])\n",
    "\n",
    "print(\"\\n=== COMPARAÇÃO DE MÉTRICAS ===\")\n",
    "print(metrics_comparison)\n",
    "print(\"\\nMelhoria relativa (%)\")\n",
    "improvement = ((metrics_comparison['Auto-Treinamento'] - metrics_comparison['Baseline (10%)']) / \n",
    "               metrics_comparison['Baseline (10%)'] * 100)\n",
    "print(improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de comparação\n",
    "metrics_comparison.plot(kind='bar', figsize=(10, 6), rot=0)\n",
    "plt.title('Comparação: Baseline vs. Auto-Treinamento', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Métrica')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Matrizes de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular matrizes de confusão\n",
    "cm_baseline = confusion_matrix(y_test, y_pred_baseline)\n",
    "cm_st = confusion_matrix(y_test, y_pred_st)\n",
    "\n",
    "# Plotar matrizes de confusão lado a lado\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Baseline\n",
    "sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'], ax=axes[0])\n",
    "axes[0].set_title('Matriz de Confusão - Baseline (10%)', fontweight='bold')\n",
    "axes[0].set_ylabel('Rótulo Verdadeiro')\n",
    "axes[0].set_xlabel('Rótulo Predito')\n",
    "\n",
    "# Auto-Treinamento\n",
    "sns.heatmap(cm_st, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'], ax=axes[1])\n",
    "axes[1].set_title('Matriz de Confusão - Auto-Treinamento', fontweight='bold')\n",
    "axes[1].set_ylabel('Rótulo Verdadeiro')\n",
    "axes[1].set_xlabel('Rótulo Predito')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Análise de Erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisar tipos de erros\n",
    "print(\"=== ANÁLISE DE ERROS ===\")\n",
    "print(\"\\nBaseline:\")\n",
    "print(f\"  Falsos Positivos (Ham classificado como Spam): {cm_baseline[0, 1]}\")\n",
    "print(f\"  Falsos Negativos (Spam classificado como Ham): {cm_baseline[1, 0]}\")\n",
    "print(f\"  Total de erros: {cm_baseline[0, 1] + cm_baseline[1, 0]}\")\n",
    "\n",
    "print(\"\\nAuto-Treinamento:\")\n",
    "print(f\"  Falsos Positivos (Ham classificado como Spam): {cm_st[0, 1]}\")\n",
    "print(f\"  Falsos Negativos (Spam classificado como Ham): {cm_st[1, 0]}\")\n",
    "print(f\"  Total de erros: {cm_st[0, 1] + cm_st[1, 0]}\")\n",
    "\n",
    "print(\"\\nRedução de erros:\")\n",
    "error_reduction = (cm_baseline[0, 1] + cm_baseline[1, 0]) - (cm_st[0, 1] + cm_st[1, 0])\n",
    "print(f\"  {error_reduction} erros a menos com auto-treinamento\")\n",
    "print(f\"  Redução de {error_reduction / (cm_baseline[0, 1] + cm_baseline[1, 0]) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusões\n",
    "\n",
    "### Observações:\n",
    "\n",
    "1. **Performance do Baseline**: Com apenas 10% dos dados rotulados, o modelo baseline já consegue uma performance razoável, mas limitada.\n",
    "\n",
    "2. **Impacto do Auto-Treinamento**: \n",
    "   - O auto-treinamento utiliza predições confiantes para expandir o conjunto de treinamento\n",
    "   - Isso permite ao modelo aprender padrões adicionais dos dados não rotulados\n",
    "   - Geralmente observamos melhoria em todas as métricas (F1, Precisão, Recall)\n",
    "\n",
    "3. **Tipos de Erros**:\n",
    "   - **Falsos Positivos**: Emails legítimos classificados como spam (incômodo para usuário)\n",
    "   - **Falsos Negativos**: Spam não detectado (risco de segurança)\n",
    "   - O auto-treinamento tende a reduzir ambos os tipos de erro\n",
    "\n",
    "4. **Limitações**:\n",
    "   - O sucesso depende da qualidade das predições iniciais\n",
    "   - Se o modelo inicial estiver muito enviesado, pode propagar erros\n",
    "   - O threshold de confiança é crucial para o desempenho\n",
    "\n",
    "5. **Aplicações Práticas**:\n",
    "   - Útil quando rotular dados é caro ou demorado\n",
    "   - Filtros de spam, detecção de fraude, classificação de documentos\n",
    "   - Cenários onde há muitos dados não rotulados disponíveis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}