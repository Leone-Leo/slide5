{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 2: Aprendizado Auto-Supervisionado com Autoencoder\n",
    "## MNIST Dataset\n",
    "\n",
    "Este notebook demonstra o uso de autoencoders para aprendizado não supervisionado usando o dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregar e Preparar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset MNIST\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "# Normalizar os dados para o intervalo [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Achatar as imagens (28x28 -> 784)\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "print(f\"Shape dos dados de treino: {x_train.shape}\")\n",
    "print(f\"Shape dos dados de teste: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definir a Arquitetura do Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensões\n",
    "input_dim = 784\n",
    "encoding_dim = 32  # Dimensão do espaço latente (compressão)\n",
    "\n",
    "# Encoder\n",
    "input_img = keras.Input(shape=(input_dim,))\n",
    "encoded = layers.Dense(128, activation='relu')(input_img)\n",
    "encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = layers.Dense(64, activation='relu')(encoded)\n",
    "decoded = layers.Dense(128, activation='relu')(decoded)\n",
    "decoded = layers.Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# Autoencoder completo\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# Modelo do Encoder separado\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# Visualizar a arquitetura\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compilar e Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar o modelo\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o autoencoder\n",
    "history = autoencoder.fit(\n",
    "    x_train, x_train,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizar o Histórico de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a perda durante o treinamento\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Treino')\n",
    "plt.plot(history.history['val_loss'], label='Validação')\n",
    "plt.title('Perda do Modelo')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Treino')\n",
    "plt.plot(history.history['val_accuracy'], label='Validação')\n",
    "plt.title('Acurácia do Modelo')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Avaliar o Autoencoder - Visualizar Reconstruções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer predições\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "# Visualizar imagens originais e reconstruídas\n",
    "n = 10  # Número de imagens a visualizar\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    # Imagem original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Imagem reconstruída\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Reconstruída\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizar o Espaço Latente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar os dados de teste\n",
    "(x_train_full, y_train_full), (x_test_full, y_test_full) = mnist.load_data()\n",
    "x_test_normalized = x_test_full.astype('float32') / 255.0\n",
    "x_test_flat = x_test_normalized.reshape((len(x_test_normalized), np.prod(x_test_normalized.shape[1:])))\n",
    "\n",
    "encoded_imgs = encoder.predict(x_test_flat)\n",
    "\n",
    "# Usar PCA para reduzir para 2D se encoding_dim > 2\n",
    "if encoding_dim > 2:\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    encoded_2d = pca.fit_transform(encoded_imgs)\n",
    "else:\n",
    "    encoded_2d = encoded_imgs\n",
    "\n",
    "# Plotar o espaço latente colorido por classe\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(encoded_2d[:, 0], encoded_2d[:, 1], c=y_test_full, cmap='tab10', alpha=0.6, s=5)\n",
    "plt.colorbar(scatter, label='Dígito')\n",
    "plt.title('Visualização do Espaço Latente (2D)')\n",
    "plt.xlabel('Dimensão 1')\n",
    "plt.ylabel('Dimensão 2')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detectar Anomalias\n",
    "\n",
    "Autoencoders podem ser usados para detecção de anomalias. Imagens com alto erro de reconstrução podem ser consideradas anomalias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular erro de reconstrução (MSE)\n",
    "mse = np.mean(np.square(x_test - decoded_imgs), axis=1)\n",
    "\n",
    "# Plotar distribuição dos erros\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(mse, bins=50, alpha=0.7, color='blue')\n",
    "plt.xlabel('Erro de Reconstrução (MSE)')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Distribuição do Erro de Reconstrução')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Identificar anomalias (top 1% de erros)\n",
    "threshold = np.percentile(mse, 99)\n",
    "anomalies = np.where(mse > threshold)[0]\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(mse, bins=50, alpha=0.7, color='blue', label='Normal')\n",
    "plt.axvline(threshold, color='red', linestyle='--', linewidth=2, label=f'Limiar (99%): {threshold:.4f}')\n",
    "plt.xlabel('Erro de Reconstrução (MSE)')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Detecção de Anomalias')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nNúmero de anomalias detectadas: {len(anomalies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar algumas anomalias\n",
    "n_anomalies = min(10, len(anomalies))\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(n_anomalies):\n",
    "    idx = anomalies[i]\n",
    "    \n",
    "    # Imagem original\n",
    "    ax = plt.subplot(2, n_anomalies, i + 1)\n",
    "    plt.imshow(x_test[idx].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"MSE: {mse[idx]:.4f}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Imagem reconstruída\n",
    "    ax = plt.subplot(2, n_anomalies, i + 1 + n_anomalies)\n",
    "    plt.imshow(decoded_imgs[idx].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Reconstruída\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('Anomalias Detectadas (Top 10)', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusões\n",
    "\n",
    "Neste notebook, demonstramos:\n",
    "\n",
    "1. **Construção de um Autoencoder**: Criamos uma rede neural que aprende a comprimir e reconstruir imagens MNIST\n",
    "2. **Aprendizado Não Supervisionado**: O modelo aprendeu representações úteis sem usar labels\n",
    "3. **Redução de Dimensionalidade**: Comprimimos imagens de 784 dimensões para 32 dimensões\n",
    "4. **Visualização do Espaço Latente**: Observamos como o modelo organiza os dígitos no espaço latente\n",
    "5. **Detecção de Anomalias**: Usamos o erro de reconstrução para identificar imagens anômalas\n",
    "\n",
    "### Possíveis Extensões:\n",
    "- Experimentar com diferentes arquiteturas (Convolutional Autoencoder, Variational Autoencoder)\n",
    "- Ajustar a dimensão do espaço latente\n",
    "- Aplicar a outros datasets\n",
    "- Usar o autoencoder para pré-treinamento em tarefas supervisionadas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
