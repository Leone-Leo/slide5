# Atividades de Machine Learning - Semi-supervisionado e Auto-supervisionado

Este reposit√≥rio cont√©m duas atividades pr√°ticas de aprendizado de m√°quina:

1. **Atividade 1**: Aprendizado Semi-supervisionado (Auto-Treinamento) com SpamBase
2. **Atividade 2**: Aprendizado Auto-supervisionado (Autoencoder) com MNIST

## üìã Requisitos

### Depend√™ncias Python

Instale as depend√™ncias necess√°rias:

```bash
pip install scikit-learn numpy pandas matplotlib seaborn tensorflow jupyter
```

Ou use o arquivo `requirements.txt`:

```bash
pip install -r requirements.txt
```

## üöÄ Como Executar

### 1. Clone o reposit√≥rio

```bash
git clone https://github.com/leone-leo/slide5.git
cd slide5
```

### 2. Instale as depend√™ncias

```bash
pip install -r requirements.txt
```

### 3. Inicie o Jupyter Notebook

```bash
jupyter notebook
```

### 4. Execute os notebooks

- **Atividade 1**: Abra `atividade1_semi_supervisionado.ipynb`
- **Atividade 2**: Abra `atividade2_auto_supervisionado.ipynb`

Execute as c√©lulas em ordem (Cell > Run All ou Shift+Enter em cada c√©lula).

## üìö Descri√ß√£o das Atividades

### Atividade 1 - Semi-supervisionado com SpamBase

**Objetivo**: Melhorar um classificador de spam usando poucos dados rotulados (10%) + pseudo-rotulagem dos dados n√£o rotulados (90%).

**Dataset**: SpamBase (OpenML id=44)
- 57 caracter√≠sticas num√©ricas
- Classifica√ß√£o bin√°ria: spam vs. n√£o-spam

**O que ser√° feito**:
1. Carregar dados e separar 10% rotulados, 90% n√£o rotulados
2. Treinar baseline (modelo supervisionado com apenas 10% dos dados)
3. Implementar auto-treinamento (self-training):
   - Fazer predi√ß√µes nos dados n√£o rotulados
   - Selecionar predi√ß√µes com alta confian√ßa
   - Adicionar ao conjunto de treinamento
   - Retreinar modelo iterativamente
4. Comparar m√©tricas (F1, precis√£o, recall)
5. Gerar matriz de confus√£o e an√°lise de erros

### Atividade 2 - Auto-supervisionado com MNIST

**Objetivo**: Aprender representa√ß√µes sem r√≥tulos via autoencoder e us√°-las em tarefas de classifica√ß√£o.

**Dataset**: MNIST
- Imagens 28√ó28 pixels
- D√≠gitos de 0 a 9

**O que ser√° feito**:
1. Carregar, normalizar e achatar imagens MNIST
2. Construir e treinar um Autoencoder:
   - Encoder: comprime a imagem para representa√ß√£o latente
   - Decoder: reconstr√≥i a imagem a partir da representa√ß√£o
3. Visualizar imagens originais vs. reconstru√≠das
4. Usar as representa√ß√µes aprendidas para classifica√ß√£o
5. Comparar classificador com features do autoencoder vs. pixels brutos

## üìÇ Estrutura do Reposit√≥rio

```
slide5/
‚îú‚îÄ‚îÄ README.md                              # Este arquivo
‚îú‚îÄ‚îÄ requirements.txt                       # Depend√™ncias Python
‚îú‚îÄ‚îÄ atividade1_semi_supervisionado.ipynb   # Notebook Atividade 1
‚îî‚îÄ‚îÄ atividade2_auto_supervisionado.ipynb   # Notebook Atividade 2
```

## üéØ Resultados Esperados

### Atividade 1
- Melhoria significativa de performance usando auto-treinamento
- F1-score do auto-treinamento > F1-score do baseline
- An√°lise de quais tipos de emails s√£o mais dif√≠ceis de classificar

### Atividade 2
- Reconstru√ß√£o visual de d√≠gitos MNIST
- Demonstra√ß√£o de que features aprendidas sem supervis√£o podem ser √∫teis
- Compara√ß√£o de performance entre diferentes abordagens


